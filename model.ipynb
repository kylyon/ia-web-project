{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66a03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2cf359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28cf6883",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True, pin_memory=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64fdf59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(training_data.classes)\n",
    "print(training_data.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a6b712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "035fe4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bd151c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,28,28,device=device)\n",
    "logits = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e6e403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1705,  0.0160,  0.0126,  0.0451, -0.0722,  0.0665, -0.0425,  0.0126,\n",
       "          0.0569, -0.0431]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b186924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1157, 0.0992, 0.0988, 0.1021, 0.0908, 0.1043, 0.0935, 0.0988, 0.1033,\n",
       "         0.0935]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8995be69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pred_probab.argmax(1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ee42151",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12a5208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size= len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss= loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss : {loss:>7f}, [{current:>5d}/{size:>5}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43f747fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size= len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct= 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            test_loss+= loss_fn(pred, y).item()\n",
    "            correct+= (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss/=num_batches\n",
    "    correct/=size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86c7ff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss : 2.301265, [   64/60000]\n",
      "loss : 2.312831, [ 6464/60000]\n",
      "loss : 2.290009, [12864/60000]\n",
      "loss : 2.294548, [19264/60000]\n",
      "loss : 2.292637, [25664/60000]\n",
      "loss : 2.280230, [32064/60000]\n",
      "loss : 2.273149, [38464/60000]\n",
      "loss : 2.272494, [44864/60000]\n",
      "loss : 2.271684, [51264/60000]\n",
      "loss : 2.276307, [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 19.4%, Avg loss: 2.264792\n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss : 2.260891, [   64/60000]\n",
      "loss : 2.257542, [ 6464/60000]\n",
      "loss : 2.255117, [12864/60000]\n",
      "loss : 2.253279, [19264/60000]\n",
      "loss : 2.247385, [25664/60000]\n",
      "loss : 2.232584, [32064/60000]\n",
      "loss : 2.232953, [38464/60000]\n",
      "loss : 2.223917, [44864/60000]\n",
      "loss : 2.221425, [51264/60000]\n",
      "loss : 2.214407, [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 2.207281\n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss : 2.222402, [   64/60000]\n",
      "loss : 2.206892, [ 6464/60000]\n",
      "loss : 2.205179, [12864/60000]\n",
      "loss : 2.187918, [19264/60000]\n",
      "loss : 2.171692, [25664/60000]\n",
      "loss : 2.174434, [32064/60000]\n",
      "loss : 2.136052, [38464/60000]\n",
      "loss : 2.155230, [44864/60000]\n",
      "loss : 2.134712, [51264/60000]\n",
      "loss : 2.112075, [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 2.114861\n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss : 2.091868, [   64/60000]\n",
      "loss : 2.098010, [ 6464/60000]\n",
      "loss : 2.110737, [12864/60000]\n",
      "loss : 2.095501, [19264/60000]\n",
      "loss : 2.091648, [25664/60000]\n",
      "loss : 2.012279, [32064/60000]\n",
      "loss : 2.035488, [38464/60000]\n",
      "loss : 2.012147, [44864/60000]\n",
      "loss : 2.033584, [51264/60000]\n",
      "loss : 2.002673, [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 1.958653\n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss : 1.932113, [   64/60000]\n",
      "loss : 1.964878, [ 6464/60000]\n",
      "loss : 1.933080, [12864/60000]\n",
      "loss : 1.894520, [19264/60000]\n",
      "loss : 1.875294, [25664/60000]\n",
      "loss : 1.795452, [32064/60000]\n",
      "loss : 1.807026, [38464/60000]\n",
      "loss : 1.812388, [44864/60000]\n",
      "loss : 1.764969, [51264/60000]\n",
      "loss : 1.724033, [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 1.712462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n--------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5558d570",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expecting a type not f<class 'typing.Union'> for typeinfo.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m example_inputs = (torch.randn(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m28\u001b[39m, \u001b[32m28\u001b[39m),)\n\u001b[32m      2\u001b[39m model.to(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m onnx_program = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43monnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamo\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Cours\\Machine Learning\\Exercice\\.venv\\Lib\\site-packages\\torch\\onnx\\__init__.py:296\u001b[39m, in \u001b[36mexport\u001b[39m\u001b[34m(model, args, f, kwargs, verbose, input_names, output_names, opset_version, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, export_params, keep_initializers_as_inputs, dynamic_axes, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Prepare legacy export parameters for potential fallback\u001b[39;00m\n\u001b[32m    287\u001b[39m     legacy_export_kwargs = {\n\u001b[32m    288\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m\"\u001b[39m: training,\n\u001b[32m    289\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33moperator_export_type\u001b[39m\u001b[33m\"\u001b[39m: operator_export_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    293\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mautograd_inlining\u001b[39m\u001b[33m\"\u001b[39m: autograd_inlining,\n\u001b[32m    294\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport_compat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_translation_table\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_translation_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexternal_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexternal_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdump_exported_program\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdump_exported_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifacts_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlegacy_export_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlegacy_export_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Cours\\Machine Learning\\Exercice\\.venv\\Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_compat.py:130\u001b[39m, in \u001b[36mexport_compat\u001b[39m\u001b[34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, custom_translation_table, dynamic_axes, dynamic_shapes, keep_initializers_as_inputs, external_data, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, legacy_export_kwargs)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    128\u001b[39m     registry_opset_version = opset_version\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m registry = \u001b[43m_registration\u001b[49m\u001b[43m.\u001b[49m\u001b[43mONNXRegistry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_torchlib\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistry_opset_version\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m custom_translation_table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m torch_op, onnx_ops \u001b[38;5;129;01min\u001b[39;00m custom_translation_table.items():\n\u001b[32m    135\u001b[39m         \u001b[38;5;66;03m# TODO(justinchuby): Support complex inputs with annotations\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Cours\\Machine Learning\\Exercice\\.venv\\Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_registration.py:169\u001b[39m, in \u001b[36mONNXRegistry.from_torchlib\u001b[39m\u001b[34m(cls, opset_version)\u001b[39m\n\u001b[32m    166\u001b[39m     registry._register(meta.fx_target, meta)\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# TODO(justinchuby): Remove this once torchlib is migrated to PyTorch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m torchlib_ops = \u001b[43monnxscript_apis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_torchlib_ops\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m torchlib_meta \u001b[38;5;129;01min\u001b[39;00m torchlib_ops:\n\u001b[32m    172\u001b[39m     qualified_name = torchlib_meta.qualified_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Cours\\Machine Learning\\Exercice\\.venv\\Lib\\site-packages\\onnxscript\\_framework_apis\\torch_2_5.py:131\u001b[39m, in \u001b[36mget_torchlib_ops\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m overload_func \u001b[38;5;129;01min\u001b[39;00m aten_overloads_func.overloads:\n\u001b[32m    128\u001b[39m     function_meta = _OnnxFunctionMeta(\n\u001b[32m    129\u001b[39m         qualified_name=qualified_name,\n\u001b[32m    130\u001b[39m         function=overload_func,\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m         domain=\u001b[43moverload_func\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunction_ir\u001b[49m.domain,\n\u001b[32m    132\u001b[39m         name=overload_func.name,\n\u001b[32m    133\u001b[39m         is_complex=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    134\u001b[39m     )\n\u001b[32m    135\u001b[39m     function_metas.append(function_meta)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m complex_func \u001b[38;5;129;01min\u001b[39;00m aten_overloads_func.complex:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Cours\\Machine Learning\\Exercice\\.venv\\Lib\\site-packages\\onnxscript\\values.py:647\u001b[39m, in \u001b[36mTracedOnnxFunction.function_ir\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    640\u001b[39m global_names.update(closure.nonlocals)\n\u001b[32m    641\u001b[39m converter = converter_module.Converter(\n\u001b[32m    642\u001b[39m     opset=\u001b[38;5;28mself\u001b[39m._opset,\n\u001b[32m    643\u001b[39m     global_names=global_names,\n\u001b[32m    644\u001b[39m     source=src,\n\u001b[32m    645\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranslate_function_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_ast\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Cours\\Machine Learning\\Exercice\\.venv\\Lib\\site-packages\\onnxscript\\converter.py:1484\u001b[39m, in \u001b[36mConverter.translate_function_signature\u001b[39m\u001b[34m(self, fn)\u001b[39m\n\u001b[32m   1482\u001b[39m domain = \u001b[38;5;28mself\u001b[39m.this_module.domain\n\u001b[32m   1483\u001b[39m \u001b[38;5;28mself\u001b[39m._current_fn = \u001b[38;5;28mself\u001b[39m.ir_builder.new_function(fn.name, domain, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_translate_function_signature_common\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Cours\\Machine Learning\\Exercice\\.venv\\Lib\\site-packages\\onnxscript\\converter.py:1427\u001b[39m, in \u001b[36mConverter._translate_function_signature_common\u001b[39m\u001b[34m(self, fn)\u001b[39m\n\u001b[32m   1420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typeinfo \u001b[38;5;129;01mand\u001b[39;00m ta.is_attr_type(typeinfo):\n\u001b[32m   1421\u001b[39m     \u001b[38;5;28mself\u001b[39m.ir_builder.add_attr_parameter(\n\u001b[32m   1422\u001b[39m         \u001b[38;5;28mself\u001b[39m._current_fn,\n\u001b[32m   1423\u001b[39m         x.arg,\n\u001b[32m   1424\u001b[39m         ta.pytype_to_attrtype(typeinfo),\n\u001b[32m   1425\u001b[39m         default_value,\n\u001b[32m   1426\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m     \u001b[38;5;28mself\u001b[39m._bind(x.arg, \u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAttrRef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypeinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_source_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28mself\u001b[39m.ir_builder.add_input(\n\u001b[32m   1430\u001b[39m         \u001b[38;5;28mself\u001b[39m._current_fn, x.arg, typeinfo, \u001b[38;5;28mself\u001b[39m._source_of(x)\n\u001b[32m   1431\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Cours\\Machine Learning\\Exercice\\.venv\\Lib\\site-packages\\onnxscript\\values.py:747\u001b[39m, in \u001b[36mAttrRef.__init__\u001b[39m\u001b[34m(self, attr_name, typeinfo, info)\u001b[39m\n\u001b[32m    744\u001b[39m \u001b[38;5;28mself\u001b[39m.typeinfo = typeinfo\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(typeinfo, (\u001b[38;5;28mtype\u001b[39m, _GenericAlias)):\n\u001b[32m    746\u001b[39m     \u001b[38;5;66;03m# typing._GenericAlias for List[int] and List[str], etc.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m747\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpecting a type not f\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(typeinfo)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for typeinfo.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    748\u001b[39m \u001b[38;5;28mself\u001b[39m.typeinfo = typeinfo\n",
      "\u001b[31mTypeError\u001b[39m: Expecting a type not f<class 'typing.Union'> for typeinfo."
     ]
    }
   ],
   "source": [
    "example_inputs = (torch.randn(1, 1, 28, 28),)\n",
    "model.to(\"cpu\")\n",
    "onnx_program = torch.onnx.export(model, example_inputs, dynamo=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
